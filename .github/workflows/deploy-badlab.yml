name: Build & Deploy BadLab

on:
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

env:
  AWS_REGION: ${{ vars.AWS_REGION }}
  AWS_ROLE_TO_ASSUME: ${{ vars.AWS_ROLE_TO_ASSUME }}
  ARTIFACT_BUCKET: ${{ vars.ARTIFACT_BUCKET }}
  STACK_NAME: ${{ vars.STACK_NAME }}
  PUBLIC_BUCKET_NAME: ${{ vars.PUBLIC_BUCKET_NAME }}

jobs:
  build-deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}
          role-session-name: gh-badlab-deploy

      - name: Show repo tree
        run: |
          pwd
          ls -lah
          echo "---- lambda/hello ----"
          find layers/vuln-py39/lambda/hello -maxdepth 2 -type f -print || true
          echo "---- layer root ----"
          find layers/vuln-py39 -maxdepth 2 -type f -print || true

      # ---------- (A) Build the vulnerable Lambda Layer ----------
      # This uses your existing layers/vuln-py39/build.sh to create vuln-py39-layer.zip
      - name: Build vulnerable layer
        working-directory: layers/vuln-py39
        run: |
          set -euo pipefail
          bash build.sh
          ls -lh *.zip

      - name: Upload layer to S3 (capture VersionId)
        working-directory: layers/vuln-py39
        run: |
          set -euo pipefail
          aws s3api put-object \
            --bucket "${ARTIFACT_BUCKET}" \
            --key "layers/vuln-py39-layer.zip" \
            --body vuln-py39-layer.zip \
            --output json > /tmp/put-layer.json
          echo "LAYER_VERSION=$(jq -r .VersionId /tmp/put-layer.json)" >> $GITHUB_ENV
          echo "LAYER_ETAG=$(jq -r .ETag /tmp/put-layer.json | tr -d '\"')" >> $GITHUB_ENV
          echo "Uploaded layer to s3://${ARTIFACT_BUCKET}/layers/vuln-py39-layer.zip"

      # ---------- (B) Build the function ZIP with vulnerable deps ----------
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Build function ZIP (with vulnerable deps)
        working-directory: layers/vuln-py39/lambda/hello
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          # Install pinned vulnerable packages into ./python
          pip install -r requirements.txt -t python
          # Package app code + site-packages
          zip -r9 function.zip index.py
          cd python && zip -r9 ../function.zip . && cd -
          ls -lh function.zip

      - name: Upload function ZIP to S3 (capture VersionId)
        working-directory: layers/vuln-py39/lambda/hello
        run: |
          set -euo pipefail
          aws s3api put-object \
            --bucket "${ARTIFACT_BUCKET}" \
            --key "function/hello.zip" \
            --body function.zip \
            --output json > /tmp/put-func.json
          echo "ZIP_VERSION=$(jq -r .VersionId /tmp/put-func.json)" >> $GITHUB_ENV
          echo "ZIP_ETAG=$(jq -r .ETag /tmp/put-func.json | tr -d '\"')" >> $GITHUB_ENV
          echo "Uploaded function ZIP to s3://${ARTIFACT_BUCKET}/function/hello.zip"

      # ---------- (C) Deploy / Update the stack ----------
      - name: Deploy CloudFormation
        run: |
          set -euo pipefail
          aws cloudformation deploy \
            --stack-name "${STACK_NAME}" \
            --template-file infra/plerion-badlab.yaml \
            --capabilities CAPABILITY_NAMED_IAM CAPABILITY_AUTO_EXPAND \
            --parameter-overrides \
              PublicBucketName="${PUBLIC_BUCKET_NAME}" \
              ArtifactBucket="${ARTIFACT_BUCKET}" \
              VulnLayerKey="layers/vuln-py39-layer.zip" \
              FuncZipKey="function/hello.zip" \
              LambdaRuntime="python3.9" \
              ApiStageName="prod" \
              DBMasterUsername="badlabuser" \
              DBMasterPassword="Pl3rionBadLab123!" \
              LastUpdatedTs="$(date +%s)"

      - name: Show stack outputs
        run: |
          aws cloudformation describe-stacks \
            --stack-name "${STACK_NAME}" \
            --query 'Stacks[0].Outputs' \
            --output table
